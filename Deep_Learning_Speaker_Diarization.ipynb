{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENldhBkJPtoW"
      },
      "source": [
        "# Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KXgi5kNMS2p",
        "outputId": "2262e604-149b-43ba-d3d4-a898b8950493",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting haystack\n",
            "  Downloading haystack-0.42-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting construct<2.8 (from haystack)\n",
            "  Downloading construct-2.5.3.tar.gz (688 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m688.1/688.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pefile (from haystack)\n",
            "  Downloading pefile-2024.8.26-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-ptrace>=0.8.1 (from haystack)\n",
            "  Downloading python_ptrace-0.9.9-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from construct<2.8->haystack) (1.17.0)\n",
            "Downloading haystack-0.42-py2.py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_ptrace-0.9.9-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pefile-2024.8.26-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.8/74.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: construct\n",
            "  Building wheel for construct (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for construct: filename=construct-2.5.3-py2.py3-none-any.whl size=71821 sha256=ce3f2bf4c7b308fcbd83e4e2f072b00712957b07c1fa441caf93438e6a123b3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/05/de/eb183fcdbac24fd9633a5a8fcc5cdd2ed5c47611683ef2f522\n",
            "Successfully built construct\n",
            "Installing collected packages: python-ptrace, pefile, construct, haystack\n",
            "Successfully installed construct-2.5.3 haystack-0.42 pefile-2024.8.26 python-ptrace-0.9.9\n",
            "Collecting assemblyai-haystack\n",
            "  Downloading assemblyai_haystack-0.1.1-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting haystack-ai (from assemblyai-haystack)\n",
            "  Downloading haystack_ai-2.13.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting assemblyai>=0.18.0 (from assemblyai-haystack)\n",
            "  Downloading assemblyai-0.40.2-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: httpx>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from assemblyai>=0.18.0->assemblyai-haystack) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1.10.17 in /usr/local/lib/python3.11/dist-packages (from assemblyai>=0.18.0->assemblyai-haystack) (2.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7 in /usr/local/lib/python3.11/dist-packages (from assemblyai>=0.18.0->assemblyai-haystack) (4.13.2)\n",
            "Requirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.11/dist-packages (from assemblyai>=0.18.0->assemblyai-haystack) (15.0.1)\n",
            "Collecting haystack-experimental (from haystack-ai->assemblyai-haystack)\n",
            "  Downloading haystack_experimental-0.10.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from haystack-ai->assemblyai-haystack) (3.1.6)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from haystack-ai->assemblyai-haystack) (4.23.0)\n",
            "Collecting lazy-imports (from haystack-ai->assemblyai-haystack)\n",
            "  Downloading lazy_imports-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from haystack-ai->assemblyai-haystack) (10.7.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from haystack-ai->assemblyai-haystack) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from haystack-ai->assemblyai-haystack) (2.0.2)\n",
            "Requirement already satisfied: openai>=1.56.1 in /usr/local/lib/python3.11/dist-packages (from haystack-ai->assemblyai-haystack) (1.78.1)\n",
            "Collecting posthog!=3.12.0 (from haystack-ai->assemblyai-haystack)\n",
            "  Downloading posthog-4.0.1-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from haystack-ai->assemblyai-haystack) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from haystack-ai->assemblyai-haystack) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from haystack-ai->assemblyai-haystack) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0 in /usr/local/lib/python3.11/dist-packages (from haystack-ai->assemblyai-haystack) (9.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from haystack-ai->assemblyai-haystack) (4.67.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai>=0.18.0->assemblyai-haystack) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai>=0.18.0->assemblyai-haystack) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai>=0.18.0->assemblyai-haystack) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai>=0.18.0->assemblyai-haystack) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.19.0->assemblyai>=0.18.0->assemblyai-haystack) (0.16.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.56.1->haystack-ai->assemblyai-haystack) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.56.1->haystack-ai->assemblyai-haystack) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.56.1->haystack-ai->assemblyai-haystack) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog!=3.12.0->haystack-ai->assemblyai-haystack) (1.17.0)\n",
            "Collecting backoff>=1.10.0 (from posthog!=3.12.0->haystack-ai->assemblyai-haystack)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.17->assemblyai>=0.18.0->assemblyai-haystack) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.17->assemblyai>=0.18.0->assemblyai-haystack) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.17->assemblyai>=0.18.0->assemblyai-haystack) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->haystack-ai->assemblyai-haystack) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->haystack-ai->assemblyai-haystack) (2.4.0)\n",
            "Collecting filetype (from haystack-experimental->haystack-ai->assemblyai-haystack)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->haystack-ai->assemblyai-haystack) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->haystack-ai->assemblyai-haystack) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->haystack-ai->assemblyai-haystack) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->haystack-ai->assemblyai-haystack) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->haystack-ai->assemblyai-haystack) (0.24.0)\n",
            "Downloading assemblyai_haystack-0.1.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading assemblyai-0.40.2-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading haystack_ai-2.13.2-py3-none-any.whl (494 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.0/494.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-4.0.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading haystack_experimental-0.10.0-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lazy_imports-0.4.0-py3-none-any.whl (12 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, lazy-imports, backoff, posthog, assemblyai, haystack-experimental, haystack-ai, assemblyai-haystack\n",
            "Successfully installed assemblyai-0.40.2 assemblyai-haystack-0.1.1 backoff-2.2.1 filetype-1.2.0 haystack-ai-2.13.2 haystack-experimental-0.10.0 lazy-imports-0.4.0 posthog-4.0.1\n",
            "Requirement already satisfied: sentence-transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=3.0.0) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=3.0.0) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=3.0.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=3.0.0) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=3.0.0) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=3.0.0) (0.31.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=3.0.0) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=3.0.0) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=3.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=3.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=3.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=3.0.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=3.0.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=3.0.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=3.0.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=3.0.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=3.0.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=3.0.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=3.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=3.0.0) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=3.0.0) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=3.0.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=3.0.0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=3.0.0) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=3.0.0) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=3.0.0) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=3.0.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=3.0.0) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: huggingface_hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (0.31.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.23.0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.23.0) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.23.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.23.0) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.23.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.23.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.23.0) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.23.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.23.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.23.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.23.0) (2025.4.26)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install haystack\n",
        "!pip install assemblyai-haystack\n",
        "!pip install \"sentence-transformers>=3.0.0\"\n",
        "!pip install \"huggingface_hub>=0.23.0\"\n",
        "!pip install --upgrade gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EN2jqFnwMN7o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "api_key = \"c6048b870abb416b896ba695c4522ec9\"\n",
        "os.environ[\"ASSEMBLYAI_API_KEY\"] = api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFQnqqnjf6_P",
        "outputId": "f43dc9df-8d03-48ae-df78-79c184b2ba06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder contents\n",
            "Processing file 12654ySXSYc2rZnPgNxXZwWt2hH-kTNDZ Netflix_Q4_2023_Earnings_Interview.mp3\n",
            "Processing file 1Zb15D_nrBzWlM3K8FuPOmyiCiYvsuJLD Panel_Discussion.mp3\n",
            "Processing file 1FFKGEZAUSmJayZgGaAe1uFP9HUtOK5m- Working_From_Home_Debate.mp3\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12654ySXSYc2rZnPgNxXZwWt2hH-kTNDZ\n",
            "To: /content/Netflix_Q4_2023_Earnings_Interview.mp3\n",
            "100% 39.1M/39.1M [00:00<00:00, 54.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Zb15D_nrBzWlM3K8FuPOmyiCiYvsuJLD\n",
            "To: /content/Panel_Discussion.mp3\n",
            "100% 21.8M/21.8M [00:00<00:00, 92.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1FFKGEZAUSmJayZgGaAe1uFP9HUtOK5m-\n",
            "To: /content/Working_From_Home_Debate.mp3\n",
            "100% 4.45M/4.45M [00:00<00:00, 90.5MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/drive/folders/10zsFuHmj3oytYMyGrLdytpW-6JzT9T_W -O \"/content\" --folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHJH9Y1HP4Hz"
      },
      "source": [
        "# Upload Audio File to AssemblyAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxMby0QqMVzN",
        "outputId": "d5556a76-3203-4a80-94ba-50676e01febd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded File URL: https://cdn.assemblyai.com/upload/94527628-3448-451d-898e-a15ed0759932\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "headers = {\n",
        "    \"authorization\": api_key,\n",
        "    \"content-type\": \"application/octet-stream\"\n",
        "}\n",
        "\n",
        "filename = \"/content/Working_From_Home_Debate.mp3\"\n",
        "\n",
        "with open(filename, \"rb\") as f:\n",
        "    response = requests.post(\"https://api.assemblyai.com/v2/upload\", headers=headers, data=f)\n",
        "\n",
        "upload_url = response.json()[\"upload_url\"]\n",
        "print(\"Uploaded File URL:\", upload_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGQKAzs_QMi7"
      },
      "source": [
        "# Submit Transcription for Speaker Diarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG15QoTnMXYh",
        "outputId": "2a41a24e-f8c3-4423-90ec-5e83431b2f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript ID: 04d48826-a2e0-4942-93ad-f09bac2df6f5\n"
          ]
        }
      ],
      "source": [
        "transcription_endpoint = \"https://api.assemblyai.com/v2/transcript\"\n",
        "\n",
        "json_data = {\n",
        "    \"audio_url\": upload_url,\n",
        "    \"speaker_labels\": True\n",
        "}\n",
        "\n",
        "transcription_headers = {\n",
        "    \"authorization\": api_key,\n",
        "    \"content-type\": \"application/json\"\n",
        "}\n",
        "\n",
        "response = requests.post(transcription_endpoint, json=json_data, headers=transcription_headers)\n",
        "transcript_id = response.json()[\"id\"]\n",
        "\n",
        "print(\"Transcript ID:\", transcript_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFVsteotQUXG"
      },
      "source": [
        "# Poll for Transcription Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbJQfeAPMaOz",
        "outputId": "576b65cf-def6-4000-8e2b-76fb7d0b466c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription processing... checking again in 10 seconds.\n",
            "Transcription completed!\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "polling_endpoint = f\"https://api.assemblyai.com/v2/transcript/{transcript_id}\"\n",
        "\n",
        "while True:\n",
        "    polling_response = requests.get(polling_endpoint, headers=transcription_headers)\n",
        "    status = polling_response.json()['status']\n",
        "\n",
        "    if status == 'completed':\n",
        "        print(\"Transcription completed!\")\n",
        "        break\n",
        "    elif status == 'error':\n",
        "        raise RuntimeError(\"Transcription failed:\", polling_response.json())\n",
        "    else:\n",
        "        print(\"Transcription processing... checking again in 10 seconds.\")\n",
        "        time.sleep(10)\n",
        "\n",
        "final_result = polling_response.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzgqtW6ZQXVb"
      },
      "source": [
        "# Display Transcript with Speaker Diarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDxGQXOKMcKt",
        "outputId": "3b938484-21df-4f64-8586-f54a690f56ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speaker A: What's the Times doing, by the way?\n",
            "Speaker B: It's such an interesting issue. The Times is asking everybody to be back three days a week. And the Guild, which represents a lot of the reporters, has balked and said we're not coming in. So there are something like 1300 guild members this week who are not going into the office. I think I continued, you know, but I'm not. I haven't been going in this week either. I just don't want to get in the middle of the fight.\n",
            "Speaker A: Yeah, wise as always. We're sort of on a three day a week plan as well here. Tuesday, Wednesday and Thursday in, and Fridays and Mondays optional. That sounds, that sounds pretty reasonable.\n",
            "Speaker B: Yeah. I can't object to that. And I have to say, from personal experience and in the reporting business, it is helpful to be with your colleagues. I would say, like two big stories I did in the last few years came through chance encounters with fellow reporters. One of them led to this, to my book, which is coming out in February. And it was all just because of a random encounter in the office that, you know, wouldn't have happened. So I'm going to be in there periodically, but of course, I only live 10 minutes away. So it's not a huge deal.\n",
            "Speaker A: It's not a big thing. You know, we hear from Tim Cook, we hear from Jamie Dimon. They seem to be saying the same things. We need you here. Collaboration is a lifeblood of our business.\n",
            "Speaker B: I think that's. I would, you know, trust them. I, look, I'm not a banker. I did work in a law firm in another life. And there, I would say collaboration also was very important. And, you know, I would take them at their word that, yeah, you know, they need, they need people in there. Now, I do feel, you know, that we've learned a lot from the pandemic, one of which is that you can trust people to make some judgments. Like it doesn't have to be five days a week, 40 hours a week. It doesn't have to be that regimented. So there is a lot of room, I think, for flexibility.\n",
            "Speaker C: You know, Jim, I'm skeptical, Tyler. And I've told our bosses this part of it is that I think you can't put the genie back in the bottle. The other thing is if you look at productivity, and we know that productivity was sustained during work from home, that it necessarily dives if people have to go home to manage their life rather than incorporating work into life at home. And the third thing, and I'm not reading anybody talking about this, but all these Companies, Apple, Starbucks, JPMorgan Chase, Goldman Sachs have very well publicized commitments to climate initiatives. I want to know about this conflict between being concerned about the environmental impact and forcing your workers to undertake, in many cases significant commuting challenges in order to just have collaboration and chance encounters in the office.\n",
            "Speaker B: Well, yeah, I think that last point is honestly not something I had pondered, but is a great point. I mean again, here in midtown Manhattan, which is, you know what, the center of a huge workforce, they're trying to put in congestion pricing to reduce the amount of transportation vehicles coming into the city. And that's completely inconsistent with going back to the old get everybody into the office all the time because a lot of them don't use mass transit. So I think that's a good question. I mean, that's a really good point. I think also though, the whole balance of power here has shifted, that the idea that there is this like top down management that orders the workforce what to do, it has really been challenged in the pandemic in a way that I would never would have dreamt possible. And I think, I think shrewd managers are going to realize that there is room for more flexibility here. I mean again, to see the personal example, if I'm hibernating and writing a story, I mean I've done all the reporting, I've had the ideas, I've been to the story meetings. All I'm doing is hibernating and writing. I'm better off at home. I mean, there are so called writing rooms in the times where people would go in there, close the door, put a do not disturb sign on there and vanish, you know, for the entire day. Now they don't need to be in the office and I'm sure there are similar situations. Maybe somebody's writing a report or doing a research thing or whatever where it's actually beneficial to be away and more productive.\n",
            "Speaker A: Agree.\n",
            "Speaker C: Can't argue with that. Agree. All right, well, I guess we're all the choir then. Thanks for preaching, Jim.\n",
            "Speaker A: Jim, thanks.\n"
          ]
        }
      ],
      "source": [
        "for utterance in final_result['utterances']:\n",
        "    speaker = utterance['speaker']\n",
        "    text = utterance['text']\n",
        "    print(f\"Speaker {speaker}: {text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identify Speaker Names"
      ],
      "metadata": {
        "id": "SrEyeox_r0k3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "url = \"https://api.worqhat.com/api/ai/content/v4\"\n",
        "\n",
        "# Improved training prompt\n",
        "training_prompt = \"\"\"\n",
        "You are an expert speaker diarizer. Your task is to identify the correct speaker names for each dialogue turn in the conversation, using clues in the language (e.g., if they mention each other by name). Return the labeled conversation in the correct sequence.\n",
        "\n",
        "You will be given a list of utterances, like this:\n",
        "[\n",
        "  {\"Speaker A\": \"Hi Jamie, how’s your day?\"},\n",
        "  {\"Speaker B\": \"Hey Alex, going well. Just prepping for the test.\"}\n",
        "]\n",
        "\n",
        "From the speech, infer who the speakers are (if names are mentioned), or label them as 'Unknown' if not clear. Do not guess names that aren’t present in the dialogue.\n",
        "\n",
        "Respond in this exact JSON format:\n",
        "[\n",
        "  {\n",
        "    \"speaker\": \"<Identified Name or 'Unknown'>\",\n",
        "    \"text\": \"<Dialogue text>\"\n",
        "  },\n",
        "  ...\n",
        "]\n",
        "\n",
        "Example:\n",
        "Input:\n",
        "[\n",
        "  {\"Speaker A\": \"What's the Times doing, by the way?\"},\n",
        "  {\"Speaker B\": \"It's such an interesting issue. The Times is asking everybody to be back three days a week.\"},\n",
        "  {\"Speaker A\": \"Yeah, wise as always.\"}\n",
        "]\n",
        "\n",
        "Output:\n",
        "[\n",
        "  {\n",
        "    \"speaker\": \"Tyler\",\n",
        "    \"text\": \"What's he doing, by the way?\"\n",
        "  },\n",
        "  {\n",
        "    \"speaker\": \"Unknown\",\n",
        "    \"text\": \"It's such an interesting issue. The Times is asking everybody to be back three days a week.\"\n",
        "  },\n",
        "  {\n",
        "    \"speaker\": \"Tyler\",\n",
        "    \"text\": \"Yeah, wise as always.\"\n",
        "  }\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "payload = {\n",
        "    \"question\": f\"Given this conversation, identify speaker names from their dialogue: {final_result['utterances']}\",\n",
        "    \"model\": \"aicon-v4-nano-160824\",\n",
        "    \"randomness\": 0.5,\n",
        "    \"stream_data\": False,\n",
        "    \"training_data\": training_prompt,\n",
        "    \"response_type\": \"json\",\n",
        "    \"conversation_id\": \"conv_1724236791746\",\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": \"Bearer wh_makph6a16JAVMlynkBDYXKqmS62QS9pgEg6surLbZ\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "# Output the response\n",
        "data = json.loads(response.text)\n",
        "print(json.dumps(data, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVQOfaboIDpU",
        "outputId": "6bfe4b71-9857-41f7-920a-7627a4ac09d4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"content\": \"[\\n  {\\n    \\\"speaker\\\": \\\"Tyler\\\",\\n    \\\"text\\\": \\\"What's the Times doing, by the way?\\\"\\n  },\\n  {\\n    \\\"speaker\\\": \\\"Jim\\\",\\n    \\\"text\\\": \\\"It's such an interesting issue. The Times is asking everybody to be back three days a week. And the Guild, which represents a lot of the reporters, has balked and said we're not coming in. So there are something like 1300 guild members this week who are not going into the office. I think I continued, you know, but I'm not. I haven't been going in this week either. I just don't want to get in the middle of the fight.\\\"\\n  },\\n  {\\n    \\\"speaker\\\": \\\"Tyler\\\",\\n    \\\"text\\\": \\\"Yeah, wise as always. We're sort of on a three day a week plan as well here. Tuesday, Wednesday and Thursday in, and Fridays and Mondays optional. That sounds, that sounds pretty reasonable.\\\"\\n  },\\n  {\\n    \\\"speaker\\\": \\\"Jim\\\",\\n    \\\"text\\\": \\\"Yeah. I can't object to that. And I have to say, from personal experience and in the reporting business, it is helpful to be with your colleagues. I would say, like two big stories I did in the last few years came through chance encounters with fellow reporters. One of them led to this, to my book, which is coming out in February. And it was all just because of a random encounter in the office that, you know, wouldn't have happened. So I'm going to be in there periodically, but of course, I only live 10 minutes away. So it's not a huge deal.\\\"\\n  },\\n  {\\n    \\\"speaker\\\": \\\"Tyler\\\",\\n    \\\"text\\\": \\\"It's not a big thing. You know, we hear from Tim Cook, we hear from Jamie Dimon. They seem to be saying the same things. We need you here. Collaboration is a lifeblood of our business.\\\"\\n  },\\n  {\\n    \\\"speaker\\\": \\\"Jim\\\",\\n    \\\"text\\\": \\\"I think that's. I would, you know, trust them. I, look, I'm not a banker. I did work in a law firm in another life. And there, I would say collaboration also was very important. And, you know, I would take them at their word that, yeah, you know, they need, they need people in there. Now, I do feel, you know, that we've learned a lot from the pandemic, one of which is that you can trust people to make some judgments. Like it doesn't have to be five days a week, 40 hours a week. It doesn't have to be that regimented. So there is a lot of room, I think, for flexibility.\\\"\\n  },\\n  {\\n    \\\"speaker\\\": \\\"Unknown\\\",\\n    \\\"text\\\": \\\"You know, Jim, I'm skeptical, Tyler. And I've told our bosses this part of it is that I think you can't put the genie back in the bottle. The other thing is if you look at productivity, and we know that productivity was sustained during work from home, that it necessarily dives if people have to go home to manage their life rather than incorporating work into life at home. And the third thing, and I'm not reading anybody talking about this, but all these Companies, Apple, Starbucks, JPMorgan Chase, Goldman Sachs have very well publicized commitments to climate initiatives. I want to know about this conflict between being concerned about the environmental impact and forcing your workers to undertake, in many cases significant commuting challenges in order to just have collaboration and chance encounters in the office.\\\"\\n  },\\n  {\\n    \\\"speaker\\\": \\\"Jim\\\",\\n    \\\"text\\\": \\\"Well, yeah, I think that last point is honestly not something I had pondered, but is a great point. I mean again, here in midtown Manhattan, which is, you know what, the center of a huge workforce, they're trying to put in congestion pricing to reduce the amount of transportation vehicles coming into the city. And that's completely inconsistent with going back to the old get everybody into the office all the time because a lot of them don't use mass transit. So I think that's a good question. I mean, that's a really good point. I think also though, the whole balance of power here has shifted, that the idea that there is this like top down management that orders the workforce what to do, it has really been challenged in the pandemic in a way that I would never would have dreamt possible. And I think, I think shrewd managers are going to realize that there is room for more flexibility here. I mean again, to see the personal example, if I'm hibernating and writing a story, I mean I've done all the reporting, I've had the ideas, I've been to the story meetings. All I'm doing is hibernating and writing. I'm better off at home. I mean, there are so called writing rooms in the times where people would go in there, close the door, put a do not disturb sign on there and vanish, you know, for the entire day. Now they don't need to be in the office and I'm sure there are similar situations. Maybe somebody's writing a report or doing a research thing or whatever where it's actually beneficial to be away and more productive.\\\"\\n  },\\n  {\\n    \\\"speaker\\\": \\\"Tyler\\\",\\n    \\\"text\\\": \\\"Agree.\\\"\\n  },\\n  {\\n    \\\"speaker\\\": \\\"Unknown\\\",\\n    \\\"text\\\": \\\"Can't argue with that. Agree. All right, well, I guess we're all the choir then. Thanks for preaching, Jim.\\\"\\n  },\\n  {\\n    \\\"speaker\\\": \\\"Tyler\\\",\\n    \\\"text\\\": \\\"Jim, thanks.\\\"\\n  }\\n]\",\n",
            "  \"processingTime\": 8717.00132,\n",
            "  \"processingId\": \"48d6d49a-6f33-4193-87ef-0f14ec9f055d\",\n",
            "  \"processingCount\": 163367,\n",
            "  \"conversation_id\": \"conv_1724236791746\",\n",
            "  \"model\": \"aicon-v4-nano-160824\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Step 1: Parse the JSON content\n",
        "raw_text = json.loads(data['content'])\n",
        "\n",
        "# Step 2: Copy the speaker and text without splitting\n",
        "formatted = []\n",
        "for entry in raw_text:\n",
        "    speaker = entry['speaker']\n",
        "    text = entry['text']\n",
        "\n",
        "    formatted.append({\n",
        "        \"speaker\": speaker,\n",
        "        \"text\": text.strip()\n",
        "    })\n",
        "\n",
        "# Step 3: Print in JSON format\n",
        "print(json.dumps(formatted, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_1hlWTcLzEG",
        "outputId": "b66b112a-655f-42fa-fa67-10c981a17fe9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"speaker\": \"Tyler\",\n",
            "    \"text\": \"What's the Times doing, by the way?\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Jim\",\n",
            "    \"text\": \"It's such an interesting issue. The Times is asking everybody to be back three days a week. And the Guild, which represents a lot of the reporters, has balked and said we're not coming in. So there are something like 1300 guild members this week who are not going into the office. I think I continued, you know, but I'm not. I haven't been going in this week either. I just don't want to get in the middle of the fight.\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Tyler\",\n",
            "    \"text\": \"Yeah, wise as always. We're sort of on a three day a week plan as well here. Tuesday, Wednesday and Thursday in, and Fridays and Mondays optional. That sounds, that sounds pretty reasonable.\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Jim\",\n",
            "    \"text\": \"Yeah. I can't object to that. And I have to say, from personal experience and in the reporting business, it is helpful to be with your colleagues. I would say, like two big stories I did in the last few years came through chance encounters with fellow reporters. One of them led to this, to my book, which is coming out in February. And it was all just because of a random encounter in the office that, you know, wouldn't have happened. So I'm going to be in there periodically, but of course, I only live 10 minutes away. So it's not a huge deal.\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Tyler\",\n",
            "    \"text\": \"It's not a big thing. You know, we hear from Tim Cook, we hear from Jamie Dimon. They seem to be saying the same things. We need you here. Collaboration is a lifeblood of our business.\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Jim\",\n",
            "    \"text\": \"I think that's. I would, you know, trust them. I, look, I'm not a banker. I did work in a law firm in another life. And there, I would say collaboration also was very important. And, you know, I would take them at their word that, yeah, you know, they need, they need people in there. Now, I do feel, you know, that we've learned a lot from the pandemic, one of which is that you can trust people to make some judgments. Like it doesn't have to be five days a week, 40 hours a week. It doesn't have to be that regimented. So there is a lot of room, I think, for flexibility.\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Unknown\",\n",
            "    \"text\": \"You know, Jim, I'm skeptical, Tyler. And I've told our bosses this part of it is that I think you can't put the genie back in the bottle. The other thing is if you look at productivity, and we know that productivity was sustained during work from home, that it necessarily dives if people have to go home to manage their life rather than incorporating work into life at home. And the third thing, and I'm not reading anybody talking about this, but all these Companies, Apple, Starbucks, JPMorgan Chase, Goldman Sachs have very well publicized commitments to climate initiatives. I want to know about this conflict between being concerned about the environmental impact and forcing your workers to undertake, in many cases significant commuting challenges in order to just have collaboration and chance encounters in the office.\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Jim\",\n",
            "    \"text\": \"Well, yeah, I think that last point is honestly not something I had pondered, but is a great point. I mean again, here in midtown Manhattan, which is, you know what, the center of a huge workforce, they're trying to put in congestion pricing to reduce the amount of transportation vehicles coming into the city. And that's completely inconsistent with going back to the old get everybody into the office all the time because a lot of them don't use mass transit. So I think that's a good question. I mean, that's a really good point. I think also though, the whole balance of power here has shifted, that the idea that there is this like top down management that orders the workforce what to do, it has really been challenged in the pandemic in a way that I would never would have dreamt possible. And I think, I think shrewd managers are going to realize that there is room for more flexibility here. I mean again, to see the personal example, if I'm hibernating and writing a story, I mean I've done all the reporting, I've had the ideas, I've been to the story meetings. All I'm doing is hibernating and writing. I'm better off at home. I mean, there are so called writing rooms in the times where people would go in there, close the door, put a do not disturb sign on there and vanish, you know, for the entire day. Now they don't need to be in the office and I'm sure there are similar situations. Maybe somebody's writing a report or doing a research thing or whatever where it's actually beneficial to be away and more productive.\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Tyler\",\n",
            "    \"text\": \"Agree.\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Unknown\",\n",
            "    \"text\": \"Can't argue with that. Agree. All right, well, I guess we're all the choir then. Thanks for preaching, Jim.\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Tyler\",\n",
            "    \"text\": \"Jim, thanks.\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Conversation Summary"
      ],
      "metadata": {
        "id": "Q8Ps1mj-2ZNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate conversation summary using WorqHat AI\n",
        "def generate_conversation_summary(formatted_conversation):\n",
        "    url = \"https://api.worqhat.com/api/ai/content/v4\"\n",
        "\n",
        "    # Create a readable conversation text from the formatted conversation\n",
        "    conversation_text = \"\"\n",
        "    for entry in formatted_conversation:\n",
        "        conversation_text += f\"{entry['speaker']}: {entry['text']}\\n\\n\"\n",
        "\n",
        "    # Craft a prompt for generating a summary\n",
        "    summary_prompt = \"\"\"\n",
        "    You are an expert at summarizing conversations. Your task is to create a concise yet comprehensive summary\n",
        "    of the conversation provided. Focus on key points, decisions, action items, and important information.\n",
        "\n",
        "    The summary should:\n",
        "    1. Be approximately 2-3 paragraphs\n",
        "    2. Highlight the main topics discussed\n",
        "    3. Note any decisions made or conclusions reached\n",
        "    4. Identify any action items or follow-ups mentioned\n",
        "    5. Maintain a neutral, professional tone\n",
        "\n",
        "    Please provide only the summary without additional commentary.\n",
        "    \"\"\"\n",
        "\n",
        "    payload = {\n",
        "        \"question\": f\"Please summarize the following conversation:\\n\\n{conversation_text}\",\n",
        "        \"model\": \"aicon-v4-nano-160824\",\n",
        "        \"randomness\": 0.3,  # Lower randomness for more factual summaries\n",
        "        \"stream_data\": False,\n",
        "        \"training_data\": summary_prompt,\n",
        "        \"response_type\": \"text\",\n",
        "        \"conversation_id\": \"conv_1724236791746\",\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": \"Bearer wh_makph6a16JAVMlynkBDYXKqmS62QS9pgEg6surLbZ\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "    # Return the summary text\n",
        "    try:\n",
        "        data = json.loads(response.text)\n",
        "        return data['content']\n",
        "    except (json.JSONDecodeError, KeyError) as e:\n",
        "        return f\"Error generating summary: {str(e)}\"\n",
        "\n",
        "# Use the function to generate a summary of your conversation\n",
        "conversation_summary = generate_conversation_summary(formatted)\n",
        "print(\"\\n\\n=== CONVERSATION SUMMARY ===\\n\")\n",
        "print(conversation_summary)"
      ],
      "metadata": {
        "id": "7-5HtlhYs1n3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e367457-33c6-4bc6-8c49-89e1b4dc0b7f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=== CONVERSATION SUMMARY ===\n",
            "\n",
            "Tyler and Jim discuss the New York Times' return-to-office policy, which requires employees to be in the office three days a week, a decision met with resistance from the union. Tyler notes his company has a similar policy. Jim argues for the importance of in-person collaboration, citing his own experiences and the views of leaders like Tim Cook and Jamie Dimon. However, he acknowledges the need for flexibility learned during the pandemic.\n",
            "\n",
            "A third speaker expresses skepticism, questioning the impact on productivity and raising concerns about the conflict between mandatory office attendance and companies' climate initiatives. Jim agrees with this point, highlighting the inconsistency with congestion pricing efforts in Manhattan. He also suggests a shift in the balance of power, with employees now expecting more flexibility. Both Tyler and the third speaker agree with Jim's points, concluding that they are \"all the choir.\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q&A"
      ],
      "metadata": {
        "id": "EJbs_zax2grY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_question_about_conversation(formatted_conversation, user_question):\n",
        "    url = \"https://api.worqhat.com/api/ai/content/v4\"\n",
        "\n",
        "    # Create a readable conversation text from the formatted conversation\n",
        "    conversation_text = \"\"\n",
        "    for entry in formatted_conversation:\n",
        "        conversation_text += f\"{entry['speaker']}: {entry['text']}\\n\\n\"\n",
        "\n",
        "    # Prompt for answering questions about the conversation\n",
        "    qa_prompt = \"\"\"\n",
        "    You are an AI assistant specialized in answering questions about meeting transcripts.\n",
        "    You have access to a meeting conversation transcript, and your task is to answer questions\n",
        "    about the content of this meeting accurately and concisely.\n",
        "\n",
        "    When answering:\n",
        "    1. Only use information explicitly mentioned in the transcript\n",
        "    2. If the answer isn't in the transcript, say \"I don't have enough information from the transcript to answer this question\"\n",
        "    3. Cite the relevant parts of the conversation by mentioning the speaker when appropriate\n",
        "    4. Keep answers concise but complete\n",
        "    5. Maintain a helpful, professional tone\n",
        "\n",
        "    Answer the question based solely on the conversation provided.\n",
        "    \"\"\"\n",
        "\n",
        "    payload = {\n",
        "        \"question\": f\"\"\"Based on the following conversation transcript, please answer this question: \"{user_question}\"\\n\\nTranscript:\\n{conversation_text}\"\"\",\n",
        "        \"model\": \"aicon-v4-nano-160824\",\n",
        "        \"randomness\": 0.2,  # Low randomness for factual answers\n",
        "        \"stream_data\": False,\n",
        "        \"training_data\": qa_prompt,\n",
        "        \"response_type\": \"text\",\n",
        "        \"conversation_id\": \"conv_1724236791746\",\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": \"Bearer wh_makph6a16JAVMlynkBDYXKqmS62QS9pgEg6surLbZ\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "    try:\n",
        "        data = json.loads(response.text)\n",
        "        return data['content']\n",
        "    except (json.JSONDecodeError, KeyError) as e:\n",
        "        return f\"Error processing question: {str(e)}\"\n",
        "\n",
        "# Function to create an interactive Q&A interface\n",
        "def interactive_meeting_qa(formatted_conversation):\n",
        "    print(\"\\n=== MEETING Q&A SYSTEM ===\")\n",
        "    print(\"Ask questions about the meeting transcript. Type 'exit' to quit.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_question = input(\"\\nYour question: \")\n",
        "\n",
        "        if user_question.lower() in ['exit', 'quit', 'q']:\n",
        "            print(\"Exiting Q&A system.\")\n",
        "            break\n",
        "\n",
        "        print(\"\\nFinding answer...\\n\")\n",
        "        answer = ask_question_about_conversation(formatted_conversation, user_question)\n",
        "        print(f\"Answer: {answer}\")\n",
        "\n",
        "# Start the interactive Q&A\n",
        "interactive_meeting_qa(formatted)"
      ],
      "metadata": {
        "id": "LSx7ytU_t-pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d77eb72e-67d2-402c-f6f1-377a720dcd7c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MEETING Q&A SYSTEM ===\n",
            "Ask questions about the meeting transcript. Type 'exit' to quit.\n",
            "\n",
            "\n",
            "Your question: What was the meeting aimed at?\n",
            "\n",
            "Finding answer...\n",
            "\n",
            "Answer: I don't have enough information from the transcript to answer this question. The conversation is about return-to-office policies, but it's not clear if this is a recording of a meeting or some other type of discussion.\n",
            "\n",
            "\n",
            "Your question: What were the discussion points?\n",
            "\n",
            "Finding answer...\n",
            "\n",
            "Answer: The discussion points were:\n",
            "\n",
            "*   **The New York Times' return-to-office policy:** The policy requires employees to be in the office three days a week, and the union's resistance to this.\n",
            "*   **The benefits of in-person collaboration:** Jim shared personal experiences of how chance encounters in the office led to important stories.\n",
            "*   **The importance of flexibility:** The speakers discussed the need for flexibility in work arrangements, especially after the pandemic.\n",
            "*   **Productivity and work-life balance:** An unnamed speaker questioned whether mandatory office attendance negatively impacts productivity and work-life balance.\n",
            "*   **Environmental impact of commuting:** The conflict between companies' climate initiatives and forcing employees to commute was raised.\n",
            "*   **Shift in the balance of power:** The speakers discussed how the pandemic may have shifted the power dynamic between employers and employees.\n",
            "\n",
            "\n",
            "Your question: What can be concluded from the meeting?\n",
            "\n",
            "Finding answer...\n",
            "\n",
            "Answer: From the conversation, it can be concluded that:\n",
            "\n",
            "*   There is a debate about the effectiveness and fairness of mandatory return-to-office policies.\n",
            "*   While in-person collaboration is valued, there are valid concerns about productivity, work-life balance, and environmental impact related to mandatory office attendance.\n",
            "*   The pandemic has potentially shifted the power dynamic between employers and employees, with employees now expecting more flexibility.\n",
            "*   A hybrid work model that balances in-person collaboration with remote work options may be a reasonable compromise.\n",
            "*   The speakers generally agree that flexibility is important and that a one-size-fits-all approach to work arrangements may not be the best solution.\n",
            "\n",
            "\n",
            "Your question: exit\n",
            "Exiting Q&A system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up a pipeline and use Named Entity Recognition to identify speaker names"
      ],
      "metadata": {
        "id": "2hsgu-HgsR8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Version 1\n",
        "\n",
        "import re\n",
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy for NER\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_md\")\n",
        "except:\n",
        "    import subprocess\n",
        "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_md\"])\n",
        "    nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "def map_speaker_labels_to_names(utterances):\n",
        "    \"\"\"\n",
        "    Map generic speaker labels (Speaker A, Speaker B, etc.) to actual names\n",
        "    based on conversation context\n",
        "\n",
        "    Args:\n",
        "        utterances: List of dictionaries with 'speaker' and 'text' keys\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping speaker labels to inferred names\n",
        "    \"\"\"\n",
        "    # Initialize speaker mapping\n",
        "    speaker_name_map = {}\n",
        "    speaker_data = {}\n",
        "    all_names = []\n",
        "    name_frequency = defaultdict(int)\n",
        "\n",
        "    # First pass: collect potential names using NER and analyze self-introductions\n",
        "    for utterance in utterances:\n",
        "        speaker_id = utterance['speaker']\n",
        "        text = utterance['text']\n",
        "\n",
        "        # Initialize speaker data if not already done\n",
        "        if speaker_id not in speaker_data:\n",
        "            speaker_data[speaker_id] = {\n",
        "                'utterances': [],\n",
        "                'mentioned_names': defaultdict(int),\n",
        "                'potential_self_names': []\n",
        "            }\n",
        "\n",
        "        speaker_data[speaker_id]['utterances'].append(text.lower())\n",
        "\n",
        "        # Process with NER to find person names\n",
        "        doc = nlp(text)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"PERSON\":\n",
        "                name = ent.text.strip()\n",
        "                # Filter out obvious non-names\n",
        "                if len(name.split()) <= 2 and len(name) > 1:\n",
        "                    all_names.append(name)\n",
        "                    name_frequency[name] += 1\n",
        "                    speaker_data[speaker_id]['mentioned_names'][name] += 1\n",
        "\n",
        "        # Check for self-introductions\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Look for patterns like \"my name is John\" or \"I'm Sarah\"\n",
        "        intro_patterns = [\n",
        "            r\"(?:^|[\\.\\?\\!]\\s+)(?:my name is|i am|i'm|this is|hello i'm|hi i'm)[\\s,]+([A-Za-z]+(?:\\s+[A-Za-z]+)?)\",\n",
        "            r\"(?:^|[\\.\\?\\!]\\s+)(?:i'm|i am)[\\s,]+([A-Za-z]+(?:\\s+[A-Za-z]+)?)\",\n",
        "            r\"(?:^|[\\.\\?\\!]\\s+)(?:hello|hi)[\\s,]+(?:my name is|i'm|i am)[\\s,]+([A-Za-z]+(?:\\s+[A-Za-z]+)?)\"\n",
        "        ]\n",
        "\n",
        "        for pattern in intro_patterns:\n",
        "            matches = re.findall(pattern, text_lower, re.IGNORECASE)\n",
        "            if matches:\n",
        "                for match in matches:\n",
        "                    potential_name = match.strip()\n",
        "                    # Verify it looks like a name\n",
        "                    if len(potential_name) > 1 and potential_name not in [\"going\", \"trying\", \"here\", \"sure\", \"glad\"]:\n",
        "                        speaker_data[speaker_id]['potential_self_names'].append(potential_name)\n",
        "\n",
        "    # Second pass: analyze speaker references\n",
        "    for i, utterance in enumerate(utterances):\n",
        "        current_speaker = utterance['speaker']\n",
        "        text = utterance['text'].lower()\n",
        "\n",
        "        # Look for handoff patterns like \"Back to you, John\"\n",
        "        handoff_patterns = [\n",
        "            r\"(?:back to you|over to you|hand it to|let's hear from|go ahead|So, )[\\s,]+([A-Za-z]+)\",\n",
        "            r\"(?:thank you|thanks)[\\s,]+([A-Za-z]+)\"\n",
        "        ]\n",
        "\n",
        "        for pattern in handoff_patterns:\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            if matches and i < len(utterances) - 1:\n",
        "                next_speaker = utterances[i+1]['speaker']\n",
        "                for match in matches:\n",
        "                    name = match.strip()\n",
        "                    if len(name) > 1 and name in all_names:\n",
        "                        speaker_name_map[next_speaker] = name.title()\n",
        "\n",
        "    # Third pass: make final decisions on speaker names\n",
        "    for speaker_id, data in speaker_data.items():\n",
        "        # If we already found a name, skip\n",
        "        if speaker_id in speaker_name_map:\n",
        "            continue\n",
        "\n",
        "        # First check self-introductions\n",
        "        if data['potential_self_names']:\n",
        "            # Use the most common name if there are multiple\n",
        "            most_common = max(data['potential_self_names'], key=data['potential_self_names'].count)\n",
        "            speaker_name_map[speaker_id] = most_common.title()\n",
        "            continue\n",
        "\n",
        "        # Look for names frequently mentioned by others but not by this speaker\n",
        "        if data['mentioned_names']:\n",
        "            # Find names that others mention when referring to this speaker\n",
        "            other_speakers_mentions = defaultdict(int)\n",
        "            for other_id, other_data in speaker_data.items():\n",
        "                if other_id != speaker_id:\n",
        "                    for name, count in other_data['mentioned_names'].items():\n",
        "                        if name not in data['mentioned_names'] or data['mentioned_names'][name] < count:\n",
        "                            other_speakers_mentions[name] += count\n",
        "\n",
        "            if other_speakers_mentions:\n",
        "                most_mentioned = max(other_speakers_mentions.items(), key=lambda x: x[1])\n",
        "                if most_mentioned[1] >= 2:  # Require at least 2 mentions\n",
        "                    speaker_name_map[speaker_id] = most_mentioned[0].title()\n",
        "\n",
        "    # Keep original speaker labels if no name was identified\n",
        "    for utterance in utterances:\n",
        "        speaker_id = utterance['speaker']\n",
        "        if speaker_id not in speaker_name_map:\n",
        "            speaker_name_map[speaker_id] = f\"Speaker {speaker_id}\"\n",
        "\n",
        "    return speaker_name_map\n",
        "\n",
        "# Main processing function\n",
        "def process_transcript(final_result):\n",
        "    # Process the utterances\n",
        "    speaker_name_map = map_speaker_labels_to_names(final_result['utterances'])\n",
        "\n",
        "    # Print the mapping\n",
        "    print(\"Speaker Identification Results:\")\n",
        "    for speaker_id, name in speaker_name_map.items():\n",
        "        print(f\"{speaker_id} → {name}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Generate the final transcript with identified names\n",
        "    print(\"Enhanced Transcript:\")\n",
        "    for utterance in final_result['utterances']:\n",
        "        speaker_id = utterance['speaker']\n",
        "        speaker_name = speaker_name_map.get(speaker_id, speaker_id)\n",
        "        text = utterance['text']\n",
        "        print(f\"{speaker_name}: {text}\")\n",
        "\n",
        "    return speaker_name_map\n",
        "\n",
        "# Run the processing\n",
        "speaker_names = process_transcript(final_result)"
      ],
      "metadata": {
        "id": "DJqQqSsjs1sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manual Approach for Speaker Name Identification"
      ],
      "metadata": {
        "id": "mDspwJNy2PaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nameparser\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_md\")"
      ],
      "metadata": {
        "id": "g6wwTKjt_feU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import spacy\n",
        "from nameparser import HumanName\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "\n",
        "try:\n",
        "    import neuralcoref  # For coreference resolution\n",
        "except ImportError:\n",
        "    neuralcoref = None\n",
        "\n",
        "try:\n",
        "    import openai  # For LLM validation\n",
        "except ImportError:\n",
        "    openai = None\n",
        "\n",
        "class SpeakerIdentifier:\n",
        "    \"\"\"Advanced speaker name identification system with multiple validation methods.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.nlp = spacy.load(\"en_core_web_md\")\n",
        "        if neuralcoref:\n",
        "            neuralcoref.add_to_pipe(self.nlp)\n",
        "\n",
        "        # Configuration\n",
        "        self.NAME_BLACKLIST = {\n",
        "            \"hi\", \"hello\", \"thanks\", \"okay\", \"yes\", \"no\", \"please\", \"ok\",\n",
        "            \"sure\", \"well\", \"right\", \"maybe\", \"actually\"\n",
        "        }\n",
        "        self.MIN_CONFIDENCE = 2  # Minimum score to accept a name mapping\n",
        "        self.INTRO_PHRASES = {\n",
        "            \"my name is\", \"i am\", \"i'm\", \"this is\", \"call me\", \"known as\",\n",
        "            \"you can call me\", \"everyone calls me\", \"they call me\"\n",
        "        }\n",
        "\n",
        "    def is_likely_name(self, text: str) -> bool:\n",
        "        \"\"\"Enhanced name validation with multiple checks.\"\"\"\n",
        "        name = HumanName(text)\n",
        "        if not name.first or len(name.first) < 2:\n",
        "            return False\n",
        "\n",
        "        lower_name = text.lower()\n",
        "        if (lower_name in self.NAME_BLACKLIST or\n",
        "            any(word in lower_name for word in self.NAME_BLACKLIST)):\n",
        "            return False\n",
        "\n",
        "        # Check for titles that might be mistaken for names\n",
        "        titles = {\"dr\", \"mr\", \"mrs\", \"ms\", \"prof\", \"professor\", \"sir\", \"madam\"}\n",
        "        if any(title in lower_name.split()[0] for title in titles):\n",
        "            return len(lower_name.split()) > 1  # Only accept if has a name part\n",
        "\n",
        "        return True\n",
        "\n",
        "    def extract_introductions(self, text: str) -> List[str]:\n",
        "        \"\"\"Extract potential names from introduction patterns.\"\"\"\n",
        "        patterns = [\n",
        "            r\"(?:{})[\\s,]+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?)\".format(\"|\".join(self.INTRO_PHRASES)),\n",
        "            r\"(?:^|\\s)(?:hi|hello|hey|greetings)[, ]+(?:i['’]?m|my name is)\\s+([A-Z][a-z]+)\",\n",
        "            r\"(?:name\\s*['’]?s\\s+([A-Z][a-z]+))\"\n",
        "        ]\n",
        "\n",
        "        names = []\n",
        "        for pattern in patterns:\n",
        "            matches = re.finditer(pattern, text, flags=re.IGNORECASE)\n",
        "            for match in matches:\n",
        "                name = match.group(1).strip()\n",
        "                if self.is_likely_name(name):\n",
        "                    names.append(name.title())\n",
        "        return names\n",
        "\n",
        "    def analyze_speaker_references(self, utterances: List[Dict]) -> Dict:\n",
        "        \"\"\"Analyze how speakers reference each other.\"\"\"\n",
        "        reference_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "        for i, utterance in enumerate(utterances):\n",
        "            speaker = utterance['speaker']\n",
        "            text = utterance['text']\n",
        "\n",
        "            # Find direct addresses (\"John, what do you think?\")\n",
        "            next_speaker = utterances[i+1]['speaker'] if i < len(utterances)-1 else None\n",
        "            direct_matches = re.finditer(\n",
        "                r\"\\b([A-Z][a-z]+)\\b,?\\s+(?:what|how|your thoughts|your opinion|you)\",\n",
        "                text, flags=re.IGNORECASE\n",
        "            )\n",
        "            for match in direct_matches:\n",
        "                name = match.group(1).title()\n",
        "                if next_speaker and self.is_likely_name(name):\n",
        "                    reference_counts[next_speaker][name] += 2\n",
        "\n",
        "            # Find thank you patterns (\"Thanks John\")\n",
        "            thanks_matches = re.finditer(\n",
        "                r\"(?:thanks|thank you|cheers)\\s+([A-Z][a-z]+)\",\n",
        "                text, flags=re.IGNORECASE\n",
        "            )\n",
        "            for match in thanks_matches:\n",
        "                name = match.group(1).title()\n",
        "                if self.is_likely_name(name):\n",
        "                    reference_counts[speaker][name] += 1  # The speaker is thanking someone\n",
        "\n",
        "        return reference_counts\n",
        "\n",
        "    def resolve_coreferences(self, utterances: List[Dict]) -> Dict:\n",
        "        \"\"\"Use coreference resolution to track pronoun references.\"\"\"\n",
        "        if not neuralcoref:\n",
        "            return {}\n",
        "\n",
        "        full_text = \" \".join([u['text'] for u in utterances])\n",
        "        doc = self.nlp(full_text)\n",
        "\n",
        "        coref_map = defaultdict(set)\n",
        "        if doc._.has_coref:\n",
        "            for cluster in doc._.coref_clusters:\n",
        "                names = [m.text for m in cluster.mentions if self.is_likely_name(m.text)]\n",
        "                if names:\n",
        "                    for mention in cluster.mentions:\n",
        "                        if mention.text.lower() in {\"he\", \"she\", \"they\"}:\n",
        "                            coref_map[mention.start_char].update(names)\n",
        "\n",
        "        return coref_map\n",
        "\n",
        "    def map_speaker_names(self, utterances: List[Dict]) -> Tuple[Dict, Dict]:\n",
        "        \"\"\"Main name mapping algorithm with confidence scoring.\"\"\"\n",
        "        speaker_evidence = defaultdict(lambda: defaultdict(int))\n",
        "        all_speaker_texts = defaultdict(list)\n",
        "\n",
        "        # First pass: collect all utterances per speaker\n",
        "        for utterance in utterances:\n",
        "            speaker = utterance['speaker']\n",
        "            text = utterance['text']\n",
        "            all_speaker_texts[speaker].append(text)\n",
        "\n",
        "        # Second pass: detect names through multiple methods\n",
        "        coref_map = self.resolve_coreferences(utterances)\n",
        "        reference_counts = self.analyze_speaker_references(utterances)\n",
        "\n",
        "        for speaker, texts in all_speaker_texts.items():\n",
        "            # Method 1: Direct introductions (highest confidence)\n",
        "            for text in texts:\n",
        "                for name in self.extract_introductions(text):\n",
        "                    speaker_evidence[speaker][name] += 3\n",
        "\n",
        "                # Method 2: NER with context analysis\n",
        "                doc = self.nlp(text)\n",
        "                for ent in doc.ents:\n",
        "                    if ent.label_ == \"PERSON\" and self.is_likely_name(ent.text):\n",
        "                        # Check if in introduction context\n",
        "                        context = doc[max(0, ent.start-3):min(len(doc), ent.end+3)].text.lower()\n",
        "                        if any(phrase in context for phrase in self.INTRO_PHRASES):\n",
        "                            speaker_evidence[speaker][ent.text.title()] += 2\n",
        "                        else:\n",
        "                            speaker_evidence[speaker][ent.text.title()] += 1\n",
        "\n",
        "                # Method 3: Coreference resolution\n",
        "                for char_pos, names in coref_map.items():\n",
        "                    if str(text) in full_text:\n",
        "                        text_start = full_text.find(str(text))\n",
        "                        if text_start <= char_pos < text_start + len(text):\n",
        "                            for name in names:\n",
        "                                speaker_evidence[speaker][name.title()] += 1\n",
        "\n",
        "            # Method 4: Cross-speaker references\n",
        "            for other_speaker, names in reference_counts.items():\n",
        "                for name, count in names.items():\n",
        "                    if other_speaker != speaker:\n",
        "                        speaker_evidence[speaker][name] += count * 0.5  # Partial credit\n",
        "\n",
        "        # Final resolution\n",
        "        speaker_mapping = {}\n",
        "        confidence_scores = {}\n",
        "\n",
        "        for speaker, names in speaker_evidence.items():\n",
        "            if names:\n",
        "                best_name, best_score = max(names.items(), key=lambda x: x[1])\n",
        "                confidence_scores[speaker] = best_score\n",
        "\n",
        "                if best_score >= self.MIN_CONFIDENCE:\n",
        "                    speaker_mapping[speaker] = best_name\n",
        "                else:\n",
        "                    # Fallback: use most mentioned name with low confidence\n",
        "                    speaker_mapping[speaker] = best_name if names else speaker\n",
        "            else:\n",
        "                speaker_mapping[speaker] = speaker\n",
        "                confidence_scores[speaker] = 0\n",
        "\n",
        "        return speaker_mapping, confidence_scores\n",
        "\n",
        "    def llm_validation(self, utterances: List[Dict], tentative_mapping: Dict,\n",
        "                      api_key: Optional[str] = None) -> Tuple[Dict, Dict]:\n",
        "        \"\"\"Validate results using GPT-4 if available.\"\"\"\n",
        "        if not openai or not api_key:\n",
        "            return tentative_mapping, {\"status\": \"LLM validation skipped\"}\n",
        "\n",
        "        try:\n",
        "            transcript = \"\\n\".join([f\"{u['speaker']}: {u['text']}\" for u in utterances])\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            Analyze this conversation and validate speaker names. Current mapping:\n",
        "            {json.dumps(tentative_mapping, indent=2)}\n",
        "\n",
        "            Transcript:\n",
        "            {transcript}\n",
        "\n",
        "            Return JSON with:\n",
        "            - \"final_mapping\": Corrected speaker names\n",
        "            - \"changes\": List of changes with explanations\n",
        "            - \"confidence\": Overall confidence (1-5)\n",
        "            \"\"\"\n",
        "\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.3,\n",
        "                max_tokens=1000\n",
        "            )\n",
        "\n",
        "            result = json.loads(response.choices[0].message.content)\n",
        "            return result.get(\"final_mapping\", tentative_mapping), result\n",
        "        except Exception as e:\n",
        "            return tentative_mapping, {\"error\": str(e)}\n",
        "\n",
        "    def process(self, utterances: List[Dict], use_llm: bool = False,\n",
        "               llm_api_key: Optional[str] = None) -> Dict:\n",
        "        \"\"\"Complete processing pipeline.\"\"\"\n",
        "        # First pass: local analysis\n",
        "        speaker_mapping, confidence_scores = self.map_speaker_names(utterances)\n",
        "\n",
        "        # Optional LLM refinement\n",
        "        llm_output = None\n",
        "        if use_llm:\n",
        "            speaker_mapping, llm_output = self.llm_validation(\n",
        "                utterances, speaker_mapping, llm_api_key\n",
        "            )\n",
        "\n",
        "        return {\n",
        "            \"speaker_mapping\": speaker_mapping,\n",
        "            \"confidence_scores\": confidence_scores,\n",
        "            \"llm_validation\": llm_output,\n",
        "            \"version\": \"1.2\"\n",
        "        }\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    example_utterances = final_result['utterances']\n",
        "\n",
        "    identifier = SpeakerIdentifier()\n",
        "    results = identifier.process(example_utterances, use_llm=False)\n",
        "\n",
        "    print(\"\\nFinal Speaker Identification Results:\")\n",
        "    for speaker, name in results[\"speaker_mapping\"].items():\n",
        "        conf = results[\"confidence_scores\"].get(speaker, 0)\n",
        "        print(f\"{speaker.ljust(10)} → {name.ljust(15)} (confidence: {conf})\")"
      ],
      "metadata": {
        "id": "hQQyM2oI81ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Version 2\n",
        "\n",
        "import re\n",
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy for NER\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_md\")\n",
        "except:\n",
        "    import subprocess\n",
        "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_md\"])\n",
        "    nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "def map_speaker_labels_to_names(utterances):\n",
        "    \"\"\"\n",
        "    Map generic speaker labels to actual names, focusing on explicit self-introductions\n",
        "\n",
        "    Args:\n",
        "        utterances: List of dictionaries with 'speaker' and 'text' keys\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping speaker labels to inferred names\n",
        "    \"\"\"\n",
        "    # Initialize speaker mapping\n",
        "    speaker_name_map = {}\n",
        "    speaker_self_intro_candidates = defaultdict(list)\n",
        "\n",
        "    # First pass: focus specifically on clear self-introductions\n",
        "    # This is now the primary identification mechanism\n",
        "    for utterance in utterances:\n",
        "        speaker_id = utterance['speaker']\n",
        "        text = utterance['text']\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # More precise introduction patterns that typically indicate clear self-identification\n",
        "        # These patterns are now more comprehensive and precise\n",
        "        intro_patterns = [\n",
        "            # Standard introduction formats\n",
        "            r\"(?:^|[\\.\\?\\!]\\s+|\\n)my name is\\s+([A-Za-z]+(?:\\s+[A-Za-z]+)?)\",\n",
        "            r\"(?:^|[\\.\\?\\!]\\s+|\\n)(?:i am|i'm)\\s+([A-Za-z]+(?:\\s+[A-Za-z]+)?)(?: and | from | with )\",\n",
        "            r\"(?:^|[\\.\\?\\!]\\s+|\\n)this is\\s+([A-Za-z]+(?:\\s+[A-Za-z]+)?)(?: speaking| here| from )\",\n",
        "\n",
        "            # Greeting with name\n",
        "            r\"(?:^|[\\.\\?\\!]\\s+|\\n)(?:hello|hi)(?:,|\\.|\\s+)?\\s+(?:my name is|i'm|i am)\\s+([A-Za-z]+(?:\\s+[A-Za-z]+)?)\",\n",
        "\n",
        "            # More formal introductions\n",
        "            r\"(?:^|[\\.\\?\\!]\\s+|\\n)(?:I would like to introduce myself|Let me introduce myself)(?:,|\\.|\\s+)?\\s+(?:my name is|i'm|i am)\\s+([A-Za-z]+(?:\\s+[A-Za-z]+)?)\",\n",
        "            r\"(?:^|[\\.\\?\\!]\\s+|\\n)(?:I'll|I will) be your\\s+.{1,20}?\\s+today(?:,|\\.|\\s+)?\\s+(?:my name is|i'm|i am)\\s+([A-Za-z]+(?:\\s+[A-Za-z]+)?)\"\n",
        "        ]\n",
        "\n",
        "        # Look for introduction patterns\n",
        "        for pattern in intro_patterns:\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                for match in matches:\n",
        "                    # If the match is a tuple (from capture groups), take the first item\n",
        "                    if isinstance(match, tuple):\n",
        "                        match = match[0]\n",
        "\n",
        "                    potential_name = match.strip()\n",
        "\n",
        "                    # More comprehensive filtering of non-names\n",
        "                    common_words = [\"going\", \"trying\", \"here\", \"sure\", \"glad\", \"sorry\",\n",
        "                                   \"just\", \"happy\", \"excited\", \"interested\", \"concerned\"]\n",
        "\n",
        "                    # Verify it looks like a name\n",
        "                    if (len(potential_name) > 1 and\n",
        "                        potential_name.lower() not in common_words and\n",
        "                        not any(char.isdigit() for char in potential_name)):\n",
        "\n",
        "                        # Store as candidate with the pattern that matched it for confidence scoring\n",
        "                        speaker_self_intro_candidates[speaker_id].append({\n",
        "                            'name': potential_name,\n",
        "                            'pattern': pattern,\n",
        "                            'text': text  # Store original text for verification\n",
        "                        })\n",
        "\n",
        "    # Second pass: verify self-introductions using NER\n",
        "    # This helps confirm that extracted phrases are actually names\n",
        "    for speaker_id, candidates in speaker_self_intro_candidates.items():\n",
        "        valid_candidates = []\n",
        "\n",
        "        for candidate in candidates:\n",
        "            potential_name = candidate['name']\n",
        "\n",
        "            # Use NER to verify it's a person name\n",
        "            doc = nlp(potential_name)\n",
        "            is_person = any(ent.label_ == \"PERSON\" for ent in doc.ents)\n",
        "\n",
        "            # Add confidence score\n",
        "            confidence = 0\n",
        "            if is_person:\n",
        "                confidence += 3  # High confidence if NER identifies as person\n",
        "\n",
        "            # More reliable introduction patterns get higher confidence\n",
        "            if \"my name is\" in candidate['pattern']:\n",
        "                confidence += 2\n",
        "            elif \"introduce myself\" in candidate['pattern']:\n",
        "                confidence += 2\n",
        "\n",
        "            # Check if the name appears in other contexts\n",
        "            name_in_other_contexts = 0\n",
        "            for utterance in utterances:\n",
        "                if utterance['speaker'] != speaker_id and potential_name.lower() in utterance['text'].lower():\n",
        "                    name_in_other_contexts += 1\n",
        "\n",
        "            # If name appears often elsewhere, slightly reduce confidence\n",
        "            if name_in_other_contexts > 3:\n",
        "                confidence -= 1\n",
        "\n",
        "            valid_candidates.append({\n",
        "                'name': potential_name,\n",
        "                'confidence': confidence,\n",
        "                'text': candidate['text']\n",
        "            })\n",
        "\n",
        "        # Select the highest confidence candidate\n",
        "        if valid_candidates:\n",
        "            best_candidate = max(valid_candidates, key=lambda x: x['confidence'])\n",
        "            if best_candidate['confidence'] > 0:\n",
        "                speaker_name_map[speaker_id] = best_candidate['name'].title()\n",
        "\n",
        "    # Third pass: for speakers without identified names, use traditional methods\n",
        "    if len(speaker_name_map) < len(set(u['speaker'] for u in utterances)):\n",
        "        # Create a list of speakers who still need names\n",
        "        unnamed_speakers = [speaker for speaker in set(u['speaker'] for u in utterances)\n",
        "                           if speaker not in speaker_name_map]\n",
        "\n",
        "        # Extract all potential person names using NER\n",
        "        all_names = []\n",
        "        name_frequency = defaultdict(int)\n",
        "\n",
        "        for utterance in utterances:\n",
        "            text = utterance['text']\n",
        "            doc = nlp(text)\n",
        "\n",
        "            # Extract person entities\n",
        "            for ent in doc.ents:\n",
        "                if ent.label_ == \"PERSON\":\n",
        "                    name = ent.text.strip()\n",
        "                    # Filter out obvious non-names\n",
        "                    if len(name.split()) <= 2 and len(name) > 1:\n",
        "                        all_names.append(name)\n",
        "                        name_frequency[name] += 1\n",
        "\n",
        "        # Look for names not yet assigned to any speaker\n",
        "        available_names = [name for name, _ in name_frequency.items()\n",
        "                          if name not in speaker_name_map.values()]\n",
        "\n",
        "        # For each unnamed speaker, try to find a name from available names\n",
        "        for speaker_id in unnamed_speakers:\n",
        "            speaker_texts = [u['text'] for u in utterances if u['speaker'] == speaker_id]\n",
        "\n",
        "            # Look for names mentioned by this speaker\n",
        "            speaker_mentioned_names = defaultdict(int)\n",
        "            for text in speaker_texts:\n",
        "                doc = nlp(text)\n",
        "                for ent in doc.ents:\n",
        "                    if ent.label_ == \"PERSON\" and ent.text in available_names:\n",
        "                        speaker_mentioned_names[ent.text] += 1\n",
        "\n",
        "            # If this speaker mentions a name frequently, it might be their own\n",
        "            if speaker_mentioned_names:\n",
        "                most_mentioned = max(speaker_mentioned_names.items(), key=lambda x: x[1])\n",
        "                if most_mentioned[1] >= 1:\n",
        "                    speaker_name_map[speaker_id] = most_mentioned[0]\n",
        "\n",
        "    # Keep original speaker labels if no name was identified\n",
        "    for utterance in utterances:\n",
        "        speaker_id = utterance['speaker']\n",
        "        if speaker_id not in speaker_name_map:\n",
        "            speaker_name_map[speaker_id] = speaker_id\n",
        "\n",
        "    return speaker_name_map\n",
        "\n",
        "# Main processing function\n",
        "def process_transcript(final_result):\n",
        "    # Process the utterances\n",
        "    speaker_name_map = map_speaker_labels_to_names(final_result['utterances'])\n",
        "\n",
        "    # Print the mapping\n",
        "    print(\"Speaker Identification Results:\")\n",
        "    for speaker_id, name in speaker_name_map.items():\n",
        "        print(f\"{speaker_id} → {name}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Generate the final transcript with identified names\n",
        "    print(\"Enhanced Transcript:\")\n",
        "    for utterance in final_result['utterances']:\n",
        "        speaker_id = utterance['speaker']\n",
        "        speaker_name = speaker_name_map.get(speaker_id, speaker_id)\n",
        "        text = utterance['text']\n",
        "        print(f\"{speaker_name}: {text}\")\n",
        "\n",
        "    return speaker_name_map\n",
        "\n",
        "# Run the processing\n",
        "speaker_names = process_transcript(final_result)"
      ],
      "metadata": {
        "id": "0dn-PrNavaF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Version 3\n",
        "\n",
        "import re\n",
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy for NER\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_md\")\n",
        "except:\n",
        "    import subprocess\n",
        "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_md\"])\n",
        "    nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "def map_speaker_labels_to_names(utterances):\n",
        "    \"\"\"\n",
        "    Map generic speaker labels to actual names based on conversation context\n",
        "\n",
        "    Args:\n",
        "        utterances: List of dictionaries with 'speaker' and 'text' keys\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping speaker labels to inferred names\n",
        "    \"\"\"\n",
        "    # Initialize speaker mapping\n",
        "    speaker_name_map = {}\n",
        "    speaker_data = {}\n",
        "    all_names = []\n",
        "    name_frequency = defaultdict(int)\n",
        "\n",
        "    # First pass: collect all potential person names using NER\n",
        "    for utterance in utterances:\n",
        "        text = utterance['text']\n",
        "        doc = nlp(text)\n",
        "\n",
        "        # Extract person entities\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"PERSON\":\n",
        "                name = ent.text.strip()\n",
        "                # Filter out obvious non-names\n",
        "                if len(name.split()) <= 2 and len(name) > 1:\n",
        "                    all_names.append(name)\n",
        "                    name_frequency[name] += 1\n",
        "\n",
        "    # Second pass: look for clear self-introductions\n",
        "    for utterance in utterances:\n",
        "        speaker_id = utterance['speaker']\n",
        "        text = utterance['text']\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Initialize speaker data if not already done\n",
        "        if speaker_id not in speaker_data:\n",
        "            speaker_data[speaker_id] = {\n",
        "                'utterances': [],\n",
        "                'mentioned_names': defaultdict(int),\n",
        "                'potential_self_names': []\n",
        "            }\n",
        "\n",
        "        speaker_data[speaker_id]['utterances'].append(text_lower)\n",
        "\n",
        "        # Process with NER to find person names mentioned by this speaker\n",
        "        doc = nlp(text)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"PERSON\":\n",
        "                name = ent.text.strip()\n",
        "                if len(name.split()) <= 2 and len(name) > 1:\n",
        "                    speaker_data[speaker_id]['mentioned_names'][name] += 1\n",
        "\n",
        "        # Look for self-introductions - careful not to capture too broad patterns\n",
        "        intro_patterns = [\n",
        "            r\"my name is\\s+([A-Za-z]+(?:\\s+[A-Za-z]+)?)\",\n",
        "            r\"(?:^|[\\.\\?\\!]\\s+)i am\\s+([A-Za-z]+(?:\\s+[A-Za-z]+)?)(?: and | from )\",\n",
        "            r\"(?:^|[\\.\\?\\!]\\s+)i'm\\s+([A-Za-z]+(?:\\s+[A-Za-z]+)?)(?: and | from )\",\n",
        "            r\"this is\\s+([A-Za-z]+(?:\\s+[A-Za-z]+)?)\\s+speaking\"\n",
        "        ]\n",
        "\n",
        "        for pattern in intro_patterns:\n",
        "            matches = re.findall(pattern, text_lower, re.IGNORECASE)\n",
        "            if matches:\n",
        "                for match in matches:\n",
        "                    # If match is a tuple, get first element\n",
        "                    if isinstance(match, tuple):\n",
        "                        match = match[0]\n",
        "\n",
        "                    potential_name = match.strip()\n",
        "                    # Verify it looks like a name\n",
        "                    common_words = [\"going\", \"trying\", \"here\", \"sure\", \"glad\", \"sorry\", \"just\", \"happy\"]\n",
        "                    if len(potential_name) > 1 and potential_name not in common_words:\n",
        "                        # Verify with NER that it's likely a person name\n",
        "                        doc = nlp(potential_name)\n",
        "                        is_person = any(ent.label_ == \"PERSON\" for ent in doc.ents)\n",
        "\n",
        "                        if is_person or potential_name in all_names:\n",
        "                            speaker_data[speaker_id]['potential_self_names'].append(potential_name)\n",
        "                            # Strong indicator of self-introduction, use immediately\n",
        "                            if \"my name is\" in pattern or \"speaking\" in pattern:\n",
        "                                speaker_name_map[speaker_id] = potential_name.title()\n",
        "\n",
        "    # If some speakers still don't have names, look at context for clues\n",
        "    for i, utterance in enumerate(utterances):\n",
        "        if i < len(utterances) - 1:  # Skip last utterance when looking ahead\n",
        "            current_speaker = utterance['speaker']\n",
        "            next_speaker = utterances[i+1]['speaker']\n",
        "\n",
        "            if current_speaker != next_speaker and current_speaker not in speaker_name_map:\n",
        "                text = utterance['text'].lower()\n",
        "\n",
        "                # Check for handoff patterns that might indicate next speaker's name\n",
        "                handoff_patterns = [\n",
        "                    r\"(?:back to you|over to you|hand it to|let's hear from|go ahead)[\\s,]+([A-Za-z]+)\",\n",
        "                    r\"(?:thank you|thanks)[\\s,]+([A-Za-z]+)\"\n",
        "                ]\n",
        "\n",
        "                for pattern in handoff_patterns:\n",
        "                    matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "                    for match in matches\n",
        "                        potential_name = match.strip()\n",
        "                        if len(potential_name) > 1 and potential_name in all_names:\n",
        "                            # This is likely referring to the next speaker\n",
        "                            speaker_name_map[next_speaker] = potential_name.title()\n",
        "\n",
        "    # Make decisions for any remaining speakers\n",
        "    for speaker_id, data in speaker_data.items():\n",
        "        # Skip if we already identified this speaker\n",
        "        if speaker_id in speaker_name_map:\n",
        "            continue\n",
        "\n",
        "        # Use self-introductions if available\n",
        "        if data['potential_self_names']:\n",
        "            most_common = max(data['potential_self_names'], key=data['potential_self_names'].count)\n",
        "            speaker_name_map[speaker_id] = most_common.title()\n",
        "            continue\n",
        "\n",
        "        # If all else fails, look at names this speaker mentions frequently\n",
        "        # but only if the name isn't already assigned to another speaker\n",
        "        if data['mentioned_names']:\n",
        "            assigned_names = set(speaker_name_map.values())\n",
        "            available_mentions = {name: count for name, count in data['mentioned_names'].items()\n",
        "                                if name.title() not in assigned_names}\n",
        "\n",
        "            if available_mentions:\n",
        "                most_mentioned = max(available_mentions.items(), key=lambda x: x[1])\n",
        "                if most_mentioned[1] >= 2:  # Require at least 2 mentions\n",
        "                    speaker_name_map[speaker_id] = most_mentioned[0].title()\n",
        "\n",
        "    # Keep original speaker labels if no name was identified\n",
        "    for utterance in utterances:\n",
        "        speaker_id = utterance['speaker']\n",
        "        if speaker_id not in speaker_name_map:\n",
        "            speaker_name_map[speaker_id] = speaker_id\n",
        "\n",
        "    return speaker_name_map\n",
        "\n",
        "# Main processing function\n",
        "def process_transcript(final_result):\n",
        "    # Process the utterances\n",
        "    speaker_name_map = map_speaker_labels_to_names(final_result['utterances'])\n",
        "\n",
        "    # Print the mapping\n",
        "    print(\"Speaker Identification Results:\")\n",
        "    for speaker_id, name in speaker_name_map.items():\n",
        "        print(f\"{speaker_id} → {name}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Generate the final transcript with identified names\n",
        "    print(\"Enhanced Transcript:\")\n",
        "    for utterance in final_result['utterances']:\n",
        "        speaker_id = utterance['speaker']\n",
        "        speaker_name = speaker_name_map.get(speaker_id, speaker_id)\n",
        "        text = utterance['text']\n",
        "        print(f\"{speaker_name}: {text}\")\n",
        "\n",
        "    return speaker_name_map\n",
        "\n",
        "# Run the processing\n",
        "speaker_names = process_transcript(final_result)"
      ],
      "metadata": {
        "id": "3BNs5esr19Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKOPkrv-jPgM"
      },
      "source": [
        "# Identify Speaker Names (Manually)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "import spacy\n",
        "\n",
        "# Load English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def identify_speakers(transcript):\n",
        "    # First pass: Find all person names and who speaks after them\n",
        "    name_mentions = defaultdict(list)\n",
        "    utterances = []\n",
        "\n",
        "    current_speaker = None\n",
        "    current_text = []\n",
        "\n",
        "    # Parse the transcript into speaker turns\n",
        "    for line in transcript.split('\\n'):\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Check for speaker label\n",
        "        speaker_match = re.match(r'^Speaker ([A-Z]):\\s*(.*)', line)\n",
        "        if speaker_match:\n",
        "            if current_speaker and current_text:\n",
        "                utterances.append((current_speaker, ' '.join(current_text)))\n",
        "            current_speaker = speaker_match.group(1)\n",
        "            current_text = [speaker_match.group(2)] if speaker_match.group(2) else []\n",
        "        else:\n",
        "            current_text.append(line)\n",
        "\n",
        "    if current_speaker and current_text:\n",
        "        utterances.append((current_speaker, ' '.join(current_text)))\n",
        "\n",
        "    # Second pass: Find name references and company affiliations\n",
        "    speaker_info = defaultdict(dict)\n",
        "\n",
        "    for i, (speaker, text) in enumerate(utterances):\n",
        "        doc = nlp(text)\n",
        "\n",
        "        # Look for direct addresses (\"Amy, what do you think?\")\n",
        "        for sent in doc.sents:\n",
        "            for token in sent:\n",
        "                if token.dep_ == \"vocative\" and token.ent_type_ == \"PERSON\":\n",
        "                    # The next speaker is likely this person\n",
        "                    if i + 1 < len(utterances):\n",
        "                        name_mentions[utterances[i+1][0]].append(token.text)\n",
        "\n",
        "        # Look for company affiliations\n",
        "        companies = [\"Shell\", \"Ocado\", \"Temenos\"]\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"ORG\" and ent.text in companies:\n",
        "                speaker_info[speaker][\"company\"] = ent.text\n",
        "\n",
        "        # Look for self-references (\"At Ocado we...\")\n",
        "        if \" at \" in text.lower() or \" from \" in text.lower():\n",
        "            for ent in doc.ents:\n",
        "                if ent.label_ == \"ORG\" and ent.text in companies:\n",
        "                    speaker_info[speaker][\"likely_company\"] = ent.text\n",
        "\n",
        "    # Third pass: Find names in context\n",
        "    for speaker, text in utterances:\n",
        "        doc = nlp(text)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"PERSON\":\n",
        "                name_mentions[speaker].append(ent.text)\n",
        "\n",
        "    # Determine most likely names\n",
        "    speaker_names = {}\n",
        "\n",
        "    # Moderator is usually Speaker A (the one asking questions)\n",
        "    speaker_names[\"A\"] = \"Moderator\"\n",
        "\n",
        "    # Assign names based on frequency and context\n",
        "    for speaker in name_mentions:\n",
        "        if speaker == \"A\":\n",
        "            continue\n",
        "\n",
        "        name_counts = defaultdict(int)\n",
        "        for name in name_mentions[speaker]:\n",
        "            name_counts[name] += 1\n",
        "\n",
        "        if name_counts:\n",
        "            most_common = max(name_counts.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "            # Verify this name is used by others to refer to this speaker\n",
        "            confirmations = 0\n",
        "            for other_speaker, other_text in utterances:\n",
        "                if f\"{most_common},\" in other_text or f\"{most_common} \" in other_text:\n",
        "                    confirmations += 1\n",
        "\n",
        "            if confirmations >= 1:  # At least one other reference\n",
        "                speaker_names[speaker] = most_common\n",
        "\n",
        "    # Fallback to company-based identification\n",
        "    company_to_name = {\n",
        "        \"Shell\": \"Amy\",\n",
        "        \"Ocado\": \"Alex\",\n",
        "        \"Temenos\": \"Tony\"\n",
        "    }\n",
        "\n",
        "    for speaker in speaker_info:\n",
        "        if speaker not in speaker_names:\n",
        "            if \"company\" in speaker_info[speaker]:\n",
        "                company = speaker_info[speaker][\"company\"]\n",
        "                speaker_names[speaker] = company_to_name.get(company, f\"Speaker {speaker}\")\n",
        "            elif \"likely_company\" in speaker_info[speaker]:\n",
        "                company = speaker_info[speaker][\"likely_company\"]\n",
        "                speaker_names[speaker] = company_to_name.get(company, f\"Speaker {speaker}\")\n",
        "\n",
        "    # Final fallback for any remaining speakers\n",
        "    for speaker in set([u[0] for u in utterances]):\n",
        "        if speaker not in speaker_names:\n",
        "            speaker_names[speaker] = f\"Speaker {speaker}\"\n",
        "\n",
        "    return speaker_names\n",
        "\n",
        "def apply_speaker_names(transcript, speaker_mapping):\n",
        "    lines = []\n",
        "    for line in transcript.split('\\n'):\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            lines.append(line)\n",
        "            continue\n",
        "\n",
        "        speaker_match = re.match(r'^(Speaker ([A-Z]):\\s*)(.*)', line)\n",
        "        if speaker_match:\n",
        "            speaker_label = speaker_match.group(2)\n",
        "            if speaker_label in speaker_mapping:\n",
        "                new_line = f\"{speaker_mapping[speaker_label]}: {speaker_match.group(3)}\"\n",
        "                lines.append(new_line)\n",
        "            else:\n",
        "                lines.append(line)\n",
        "        else:\n",
        "            lines.append(line)\n",
        "\n",
        "    return '\\n'.join(lines)\n",
        "\n",
        "# Process the transcript\n",
        "speaker_mapping = identify_speakers(transcript_text)\n",
        "named_transcript = apply_speaker_names(transcript_text, speaker_mapping)\n",
        "\n",
        "print(\"Identified Speaker Mapping:\")\n",
        "print(speaker_mapping)\n",
        "print(\"\\nTranscript with Speaker Names:\")\n",
        "print(named_transcript)"
      ],
      "metadata": {
        "id": "uP3MzQk5k1_i"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "mDspwJNy2PaF",
        "wKOPkrv-jPgM"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}